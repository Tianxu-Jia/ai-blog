{
  "hash": "7d074078179aa221993a8d26b6065890",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"How to debug Chainlit App like normal Python code\"\nauthor: \"Tianxu Jia\"\ntoc: true\nnumber-sections: true\ndate: today\ncategories: [memo]\n---\n\n![](memo.jpg)\n\n## Introduction\n    Chainlit is an open-source Python framework designed to streamline the development and monitoring of conversational applications. It focuses on building apps that interact with large language models (LLMs) like ChatGPT or Bard, allowing you to easily create interfaces and manage the user experience.\n\n    Debugging Chainlit apps presents challenges due to limited breakpoint functionality. The code below shows how to debug it like normal Python code. Once thoroughly tested, integration into the LLM app can proceed.\n\n## Code\n\n::: {#187c40bd .cell execution_count=1}\n``` {.python .cell-code}\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Sun Jan 14 09:55:19 2024\n\n@author: txjia\n\"\"\"\n\nfrom autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager, ConversableAgent\n#from decouple import config\nimport chainlit as cl\n\n\ndef chat_new_message(self, message, sender):\n    cl.run_sync(\n        cl.Message(\n            content=\"\",\n            author=sender.name,\n        ).send()\n    )\n    print(message)\n    print(type(message))\n    #content = message.get(\"content\")\n    content = message\n    cl.run_sync(\n        cl.Message(\n            content=content,\n            author=sender.name,\n        ).send()\n    )\n\n\ndef config_personas():\n    #config_list = [{\n    #    \"model\": \"gpt-3.5-turbo-1106\",  # model name\n    #    \"api_key\": config(\"OPENAI_API_KEY\")  # api key\n    #}]\n    config_list = [\n        {\n            'base_url': \"http://0.0.0.0:8000\", \n            'api_key': \"sk-xxxxxx\",\n            'model': \"gpt-3.5-turbo\",\n        }\n    ]\n\n\n    llm_config = {\n        #\"seed\": 14,  # seed for caching and reproducibility\n        \"config_list\": config_list,  # a list of OpenAI API configurations\n        \"temperature\": 0.7,  # temperature for sampling\n    }\n\n    user_proxy = UserProxyAgent(\n        name=\"Admin\",\n        system_message=\"A human admin. Interact with the planner to discuss the plan. \"\n                       \"Plan execution needs to be approved by this admin.\",\n        code_execution_config=False,\n        max_consecutive_auto_reply=10,\n        llm_config=llm_config,\n        human_input_mode=\"NEVER\"\n    )\n\n    engineer = AssistantAgent(\n        name=\"Engineer\",\n        llm_config=llm_config,\n        system_message='''Engineer. You follow an approved plan. You write python/shell code to solve tasks. Wrap the \n        code in a code block that specifies the script type. The user can't modify your code. So do not suggest \n        incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by \n        the executor. Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. \n        Check the execution result returned by the executor. If the result indicates there is an error, fix the error and \n        output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed \n        or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your \n        assumption, collect additional info you need, and think of a different approach to try.''',\n    )\n\n    planner = AssistantAgent(\n        name=\"Planner\",\n        system_message='''Planner. Suggest a plan. Revise the plan based on feedback from admin and critic, until admin \n        approval. The plan may involve an engineer who can write code and an executor and critic who doesn't write code. \n        Explain the plan first. Be clear which step is performed by an engineer, executor, and critic.''',\n        llm_config=llm_config,\n    )\n\n    executor = AssistantAgent(\n        name=\"Executor\",\n        system_message=\"Executor. Execute the code written by the engineer and report the result.\",\n        code_execution_config={\"last_n_messages\": 3, \"work_dir\": \"feedback\"},\n        llm_config=llm_config,\n    )\n\n    critic = AssistantAgent(\n        name=\"Critic\",\n        system_message=\"Critic. Double check plan, claims, code from other agents and provide feedback.\",\n        llm_config=llm_config,\n    )\n\n    group_chat = GroupChat(agents=[user_proxy, engineer, planner, executor, critic], messages=[], max_round=50)\n    manager = GroupChatManager(groupchat=group_chat, llm_config=llm_config)\n\n    return user_proxy, manager\n\n\ndef start_chat_saas(message, is_test=False):\n    if not is_test:\n        ConversableAgent._print_received_message = chat_new_message\n    user_proxy, manager = config_personas()\n    user_proxy.initiate_chat(manager, message=message)\n\n\nif __name__ == \"__main__\":\n    test_message = (\n        \"I would like to build a simple website that collects feedback from \"\n        \"consumers via forms.  We can just use a flask application that creates an \"\n        \"html website with forms and has a single question if they liked their \"\n        \"customer experience and then keeps that answer.  I need a thank you html \"\n        \"page once they completed the survey.  I then need a html page called \"\n        \"admin that gives a nice table layout of all of the records from the \"\n        \"database.  Just use sqlite3 as the database, keep it simple.  Also use \"\n        \"Bootstrap for the CSS Styling.\")\n    #start_chat_saas(test_message, is_test=True)\n    start_chat_saas(test_message, is_test=True)\n```\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}